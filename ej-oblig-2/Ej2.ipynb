{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hola\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "file_name = 'europe.csv'\n",
    "# data = pandas.read_csv(file_name)\n",
    "#\n",
    "# country_list = data[\"Country\"].tolist()\n",
    "# area_list = data[\"Area\"].tolist()\n",
    "# gdp_list = data[\"GDP\"].tolist()\n",
    "# inflation_list = data[\"Inflation\"].tolist()\n",
    "# life_expect_list = data[\"Life.expect\"].tolist()\n",
    "# military_list = data[\"Military\"].tolist()\n",
    "# pop_growth_list = data[\"Pop.growth\"].tolist()\n",
    "# unemployment_list = data[\"Unemployment\"].tolist()\n",
    "\n",
    "feature_names = [\"Area\",\"GDP\",\"Inflation\",\"Life.expect\",\"Military\",\"Pop.growth\",\"Unemployment\"] # without country\n",
    "data = pandas.read_csv(file_name)\n",
    "\n",
    "# feature_sets = data.drop('Country', 1)\n",
    "# labels = data['Country']\n",
    "\n",
    "\n",
    "print(\"Hola\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'data'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[0;32m~/dev/sia/ej-oblig-2/venv/lib/python3.8/site-packages/pandas/core/indexes/base.py:3621\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n\u001B[1;32m   3620\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 3621\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3622\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[0;32mpandas/_libs/index.pyx:136\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/index.pyx:163\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:5198\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:5206\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: 'data'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Input \u001B[0;32mIn [2]\u001B[0m, in \u001B[0;36m<cell line: 6>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpreprocessing\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m StandardScaler\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# Construct a dataframe using pandas\u001B[39;00m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;66;03m# FIXME: sera necesario un dataframe?\u001B[39;00m\n\u001B[0;32m----> 6\u001B[0m df \u001B[38;5;241m=\u001B[39m pandas\u001B[38;5;241m.\u001B[39mDataFrame(\u001B[43mdata\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mdata\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m, columns\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfeature_names\u001B[39m\u001B[38;5;124m'\u001B[39m)    \u001B[38;5;66;03m# TODO: data?\u001B[39;00m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;66;03m# Scale data before applying PCA\u001B[39;00m\n\u001B[1;32m      9\u001B[0m standard_scaler \u001B[38;5;241m=\u001B[39m StandardScaler()\n",
      "File \u001B[0;32m~/dev/sia/ej-oblig-2/venv/lib/python3.8/site-packages/pandas/core/frame.py:3505\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3503\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m   3504\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[0;32m-> 3505\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3506\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[1;32m   3507\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[0;32m~/dev/sia/ej-oblig-2/venv/lib/python3.8/site-packages/pandas/core/indexes/base.py:3623\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n\u001B[1;32m   3621\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine\u001B[38;5;241m.\u001B[39mget_loc(casted_key)\n\u001B[1;32m   3622\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[0;32m-> 3623\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[1;32m   3624\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m   3625\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[1;32m   3626\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[1;32m   3627\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[1;32m   3628\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
      "\u001B[0;31mKeyError\u001B[0m: 'data'"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Construct a dataframe using pandas\n",
    "# FIXME: sera necesario un dataframe?\n",
    "df = pandas.DataFrame(data['data'], columns='feature_names')    # TODO: data?\n",
    "\n",
    "# Scale data before applying PCA\n",
    "standard_scaler = StandardScaler()\n",
    "\n",
    "standard_scaler.fit(df)\n",
    "scaled_data = standard_scaler.transform(df)\n",
    "\n",
    "pca = PCA(n_components=1)\n",
    "pca.fit(scaled_data)\n",
    "x = pca.transform(scaled_data)\n",
    "\n",
    "# Check the dimensions of data after PCA\n",
    "print(x.shape)\n",
    "\n",
    "# Check the values of eigen vectors produced by principal components\n",
    "print(pca.components_)\n",
    "\n",
    "# Check how much variance is explained by each principal component\n",
    "print(pca.explained_variance_ratio_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['malignant' 'benign']\n",
      "['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n"
     ]
    }
   ],
   "source": [
    "# TODO: DELETE\n",
    "\n",
    "# Example from\n",
    "# https://www.geeksforgeeks.org/implementing-pca-in-python-with-scikit-learn/\n",
    "\n",
    "# import all libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#import the breast _cancer dataset\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "data=load_breast_cancer()\n",
    "data.keys()\n",
    "\n",
    "# Check the output classes\n",
    "print(data['target_names'])\n",
    "\n",
    "# Check the input attributes\n",
    "print(data['feature_names'])\n",
    "\n",
    "# construct a dataframe using pandas\n",
    "df1=pd.DataFrame(data['data'],columns=data['feature_names'])\n",
    "\n",
    "# Scale data before applying PCA\n",
    "scaling=StandardScaler()\n",
    "\n",
    "# Use fit and transform method\n",
    "scaling.fit(df1)\n",
    "Scaled_data=scaling.transform(df1)\n",
    "\n",
    "# Set the n_components=3\n",
    "principal=PCA(n_components=3)\n",
    "principal.fit(Scaled_data)\n",
    "x=principal.transform(Scaled_data)\n",
    "\n",
    "# Check the dimensions of data after PCA\n",
    "print(x.shape)\n",
    "\n",
    "# Check the values of eigen vectors\n",
    "# produced by principal components\n",
    "print(principal.components_)\n",
    "\n",
    "# plot the components\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(x[:,0],x[:,1],c=data['target'],cmap='plasma')\n",
    "plt.xlabel('pc1')\n",
    "plt.ylabel('pc2')\n",
    "\n",
    "# check how much variance is explained by each principal component\n",
    "print(principal.explained_variance_ratio_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}